{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.6/importlib/_bootstrap.py:219: RuntimeWarning: numpy.ufunc size changed, may indicate binary incompatibility. Expected 192 from C header, got 216 from PyObject\n",
      "  return f(*args, **kwds)\n",
      "/opt/conda/lib/python3.6/importlib/_bootstrap.py:219: RuntimeWarning: numpy.ufunc size changed, may indicate binary incompatibility. Expected 192 from C header, got 216 from PyObject\n",
      "  return f(*args, **kwds)\n",
      "/opt/conda/lib/python3.6/importlib/_bootstrap.py:219: RuntimeWarning: numpy.ufunc size changed, may indicate binary incompatibility. Expected 192 from C header, got 216 from PyObject\n",
      "  return f(*args, **kwds)\n",
      "/opt/conda/lib/python3.6/importlib/_bootstrap.py:219: RuntimeWarning: numpy.ufunc size changed, may indicate binary incompatibility. Expected 192 from C header, got 216 from PyObject\n",
      "  return f(*args, **kwds)\n"
     ]
    }
   ],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(action='once')\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "InteractiveShell.ast_node_interactivity = \"all\"\n",
    "import pickle\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline\n",
    "from exp.misc import *\n",
    "from exp.ProcessData import *\n",
    "from exp.PytorchModels import *\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.utils.data as D\n",
    "import torch.nn.functional as F\n",
    "import copy\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "# from exp.misc import *\n",
    "# from exp.ProcessData import *\n",
    "# from exp.PytorchModels import *\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.utils.data as D\n",
    "import torch.nn.functional as F\n",
    "import copy\n",
    "import numpy as np\n",
    "try:\n",
    "    from torch.cuda.amp import autocast,GradScaler\n",
    "except:\n",
    "    print('warning amp is not usable')\n",
    "    autocast=None\n",
    "    GradScaler=None\n",
    "from tqdm import notebook\n",
    "\n",
    "import urllib.request\n",
    "def check_internet(host='http://google.com'):\n",
    "    try:\n",
    "        urllib.request.urlopen(host) #Python 3.x\n",
    "        return True\n",
    "    except:\n",
    "        return False\n",
    "class DummySend:\n",
    "    def send(self,*args):\n",
    "        print(*args)\n",
    "if check_internet():\n",
    "    try:\n",
    "        import sandesh\n",
    "    except:\n",
    "        sandesh=DummySend()\n",
    "else:\n",
    "    sandesh=DummySend()\n",
    "    \n",
    "class Learner(object):\n",
    "    def __init__(self,model,optimizer,loss_func,name=\"\",scheduler=None,device='cpu'):\n",
    "        self.model=model\n",
    "        self.optimizer=optimizer\n",
    "        self.loss_func=loss_func\n",
    "        self.scheduler=scheduler\n",
    "        self.scaler=None\n",
    "        self.device=device\n",
    "        self.metric=None\n",
    "        self.name=name\n",
    "        self.log={}\n",
    "        self.eth=0.99\n",
    "        self.do_autocast=False\n",
    "\n",
    "    def init_amp(self,init_scale=65536.0, growth_factor=2.0, backoff_factor=0.5, \n",
    "                 growth_interval=2000, enabled=True,do_autocast=True):\n",
    "        self.do_autocast=do_autocast\n",
    "        if GradScaler is not None:\n",
    "            self.scaler=GradScaler(init_scale=init_scale, growth_factor=growth_factor,\n",
    "                               backoff_factor=backoff_factor, growth_interval=growth_interval, enabled=True)\n",
    "        \n",
    "    def get_y(self,batch):\n",
    "        # get Y from Batch, the default is batch[-1] but you can overwrite it\n",
    "        return batch[-1]\n",
    "\n",
    "    def get_inds(self,batch):\n",
    "        # get Y from Batch, the default is batch[-1] but you can overwrite it\n",
    "        return batch[-1]\n",
    " \n",
    "    def get_x(self,batch):\n",
    "        # get x from Batch, the default is batch[:-1] but you can overwrite it\n",
    "        if isinstance(batch,(list,tuple)):\n",
    "            return batch[:-1]\n",
    "        else:\n",
    "            return [batch]\n",
    "        \n",
    "    def run_model(self,model,batch):\n",
    "        return model(*(x.to(self.device) for x in self.get_x(batch)))\n",
    "    \n",
    "    def calc_loss(self,y_pred,y_true):\n",
    "        return self.loss_func(y_pred,y_true.to(self.device))\n",
    "\n",
    "    def one_cycle(self,batch,train=True,do_step=True):\n",
    "        device = self.device\n",
    "        self.preprocess_batch(batch,train)\n",
    "        y_true=self.get_y(batch)\n",
    "        if autocast is None:\n",
    "            y_pred= self.run_model(self.model,batch) \n",
    "            loss = self.calc_loss(y_pred,y_true)\n",
    "            loss_item = 0 if np.isnan(loss.item()) else loss.item()\n",
    "        else:\n",
    "            with autocast(self.do_autocast):\n",
    "                y_pred= self.run_model(self.model,batch) \n",
    "                loss = self.calc_loss(y_pred,y_true)\n",
    "                loss_item = 0 if np.isnan(loss.item()) else loss.item()\n",
    "        if train:\n",
    "            if self.scaler is not None:\n",
    "                self.scaler.scale(loss).backward()\n",
    "            else:\n",
    "                loss.backward()\n",
    "            if do_step:\n",
    "                if self.scaler is not None:\n",
    "                    self.scaler.step(self.optimizer)\n",
    "                    self.scaler.update()\n",
    "                else:\n",
    "                    self.optimizer.step()\n",
    "                if self.scheduler is not None:\n",
    "                    self.scheduler.step()\n",
    "                self.optimizer.zero_grad()\n",
    "            if np.isnan(loss.item()):\n",
    "                print('got loss = nan')\n",
    "            loss_item = 0 if np.isnan(loss.item()) else loss.item()\n",
    "        return loss_item if train else (loss_item, y_pred.to('cpu').detach())\n",
    "\n",
    "\n",
    "    def one_training_epoch(self, dl, accumulation_steps=1):\n",
    "        device = self.device\n",
    "        torch.cuda.empty_cache()\n",
    "        avg_loss = 0.\n",
    "        lossf=0.\n",
    "        self.model=self.model.train()\n",
    "        self.model.zero_grad()\n",
    "        tk0 = notebook.tqdm(dl)\n",
    "        for i,batch in enumerate(tk0):\n",
    "            do_step = (i+1) % accumulation_steps == 0\n",
    "            loss_item = self.one_cycle(batch, train=True, do_step=do_step)\n",
    "            e=min(self.eth,1-1.0/(i+1.0))\n",
    "            lossf = e*lossf+(1-e)*loss_item \n",
    "            tk0.set_postfix(loss = lossf)\n",
    "            avg_loss += loss_item / len(dl)\n",
    "        tk0.disable=False\n",
    "        tk0.set_postfix(loss = avg_loss)\n",
    "        tk0.disable=True\n",
    "        return avg_loss\n",
    "\n",
    "    def agg_tta(self,y):\n",
    "        return np.stack(y,0).mean(0) if not isinstance(y[0],tuple)\\\n",
    "               else tuple(np.stack([yy[i] for yy in y],0).mean(0) for i in range(len(y[0]))) \n",
    "\n",
    "        \n",
    "    def preprocess_batch(self,batch,train=True):\n",
    "        return(batch)\n",
    "        \n",
    "    def one_eval_epoch(self, dl,tta=1):\n",
    "        device = self.device\n",
    "        avg_loss = 0.\n",
    "        avg_accuracy = 0.\n",
    "        lossf=0\n",
    "        self.model=self.model.eval()\n",
    "        predss=[]\n",
    "        with torch.no_grad():\n",
    "            for t in range(tta):\n",
    "                pred_list=[]\n",
    "                true_list=[]\n",
    "                tk0 = notebook.tqdm(dl)\n",
    "                for i,batch in enumerate(tk0):\n",
    "                    loss_item, y_pred = self.one_cycle(batch, train=False, do_step=False)\n",
    "                    pred_list.append(y_pred.to('cpu').numpy() if not isinstance(y_pred,tuple) else\\\n",
    "                        tuple(y.to('cpu').numpy() for y in y_pred))\n",
    "                    y_batch=self.get_y(batch)\n",
    "                    true_list.append(y_batch.to('cpu').numpy() if not isinstance(y_batch,tuple) else\\\n",
    "                        tuple(y.to('cpu').numpy() for y in y_batch))\n",
    "                    e=min(self.eth,1-1.0/(i+1.0))\n",
    "                    lossf = e*lossf+(1-e)*loss_item \n",
    "                    tk0.set_postfix(loss = lossf)\n",
    "                    avg_loss += loss_item / len(dl)\n",
    "#                 y_true=np.concatenate(true_list,0)\n",
    "                y_true=np.concatenate(true_list,0) if not isinstance(true_list[0],tuple) else\\\n",
    "                    tuple(np.concatenate([p[i] for p in true_list],0) for i in range(len(true_list[0])))\n",
    "                predss.append(np.concatenate(pred_list,0) if not isinstance(pred_list[0],tuple) else\\\n",
    "                    tuple(np.concatenate([p[i] for p in pred_list],0) for i in range(len(pred_list[0]))))\n",
    "\n",
    "            preds=self.agg_tta(predss,0) if tta>1 else predss[0]\n",
    "            m= dict() if self.metric is None else self.metric(preds,y_true)\n",
    "        tk0.disable=False\n",
    "        tk0.set_postfix(loss = avg_loss, **m)\n",
    "        tk0.disable=True\n",
    "        return avg_loss, m\n",
    "    \n",
    "    def send_log(self,**kwargs):\n",
    "        log={'model':self.name}\n",
    "        log.update(kwargs)\n",
    "        try:\n",
    "            sandesh.send(log)\n",
    "        except:\n",
    "            print(log)\n",
    "        \n",
    "    def save2log(self,**kwargs):\n",
    "        for key in kwargs.keys():\n",
    "            if key not in self.log:\n",
    "                self.log[key]=[]\n",
    "            self.log[key].append(kwargs[key])\n",
    "    \n",
    "    def evaluate(self,ds,num_workers=8,tta=1,dl_args={'shuffle':False}):\n",
    "            dl=D.DataLoader(ds,num_workers=num_workers,**dl_args)\n",
    "            return self.one_eval_epoch(dl,tta=tta)\n",
    "\n",
    "    \n",
    "    def fit(self,num_epoches,train_ds,validate_ds=None,batch_size=None,lr=None,accumulation_steps=1,\n",
    "            num_workers=8,send_log=True,eval_batch=None,reset_best=False,make_best=True,tta=1,\n",
    "            train_dl_args={'shuffle':True},val_dl_args={'shuffle':False},save_checkpoint='best',path=''):\n",
    "        if batch_size is not None:\n",
    "            train_dl_args['batch_size']=batch_size\n",
    "            val_dl_args['batch_size']=batch_size\n",
    "        if eval_batch is not None:\n",
    "            val_dl_args['batch_size']=eval_batch\n",
    "\n",
    "        tq = notebook.tqdm(range(num_epoches))\n",
    "        if lr is not None:\n",
    "            self.set_lr(lr)\n",
    "        if reset_best or not hasattr(self,'best_metric'):\n",
    "            self.best_model=None\n",
    "            self.best_metric=np.inf\n",
    "        for k,epoch in enumerate(tq):\n",
    "            self.on_epoch_begin(epoch,train_ds=train_ds,validate_ds=validate_ds)\n",
    "            dl=D.DataLoader(train_ds, num_workers=num_workers,**train_dl_args)\n",
    "            if next(self.model.parameters()).device!=torch.device('cpu'):\n",
    "                torch.cuda.empty_cache()\n",
    "            tavg_loss=self.one_training_epoch(dl,accumulation_steps=accumulation_steps)\n",
    "#             dl=D.DataLoader(validate_ds, batch_size=batch_size if eval_batch is None else eval_batch, \n",
    "#                              num_workers=num_workers,**val_dl_args)\n",
    "            if validate_ds is not None:\n",
    "                avg_loss , metric =self.evaluate(validate_ds,  \n",
    "                                 num_workers=num_workers,dl_args=val_dl_args, tta=tta)\n",
    "            else:\n",
    "                avg_loss=tavg_loss\n",
    "                metric={}\n",
    "            if send_log:\n",
    "                self.send_log(epoch=epoch,tloss=tavg_loss,loss=avg_loss,**metric)\n",
    "            self.save2log(epoch=epoch,tloss=tavg_loss,loss=avg_loss,**metric)\n",
    "            m = avg_loss  if 'metric' not in metric.keys() else metric['metric']\n",
    "            if save_checkpoint=='last':\n",
    "                self.save_checkpoint(path)\n",
    "            if m<self.best_metric:\n",
    "                self.best_metric=m\n",
    "                self.best_model = copy.deepcopy(self.model.state_dict())\n",
    "                tq.set_postfix(best_metric=self.best_metric)\n",
    "                if save_checkpoint=='best':\n",
    "                    self.save_checkpoint(path)\n",
    "            self.on_epoch_end(epoch)\n",
    "            \n",
    "        print ('best metric:',self.best_metric)\n",
    "        if make_best:\n",
    "            self.model.load_state_dict(self.best_model)\n",
    "        \n",
    "    def save_model(self,path,name=None):\n",
    "        name = self.name if name is None else name\n",
    "        torch.save(self.model.state_dict(),f'{path}{name}')\n",
    "        \n",
    "    def load_model(self,path,name=None,map_location=None):\n",
    "        name = self.name if name is None else name\n",
    "        self.model.load_state_dict(torch.load(f'{path}{name}',map_location=map_location))\n",
    "        \n",
    "           \n",
    "    def save_checkpoint(self,path,name=None):\n",
    "        name = self.name+'.chk' if name is None else name\n",
    "        checkpoint={\n",
    "                'model': self.model.state_dict(),\n",
    "                'best_model': self.best_model,\n",
    "                'best_metric': self.best_metric,\n",
    "                'model': self.model.state_dict(),\n",
    "                'optimizer': self.optimizer.state_dict(),\n",
    "                'log' : self.log\n",
    "                }\n",
    "        if self.scaler:\n",
    "            checkpoint['scaler']=self.scaler.state_dict()\n",
    "        torch.save(checkpoint,f'{path}{name}')\n",
    "\n",
    "    def load_checkpoint(self,path,name=None):\n",
    "        name = self.name+'.chk' if name is None else name+'.chk'\n",
    "        checkpoint=torch.load(f'{path}{name}')\n",
    "        self.model.load_state_dict(checkpoint['model'])\n",
    "        self.best_model=checkpoint['best_model']\n",
    "        self.best_metric=checkpoint['best_metric']\n",
    "        self.optimizer.load_state_dict(checkpoint['optimizer'])\n",
    "        self.log=checkpoint['log']\n",
    "        if 'scaler' in checkpoint.keys():\n",
    "            self.scaler=GradScaler()\n",
    "            self.scaler.load_state_dict(checkpoint['scaler'])\n",
    "        else:\n",
    "            self.scaler=None\n",
    "       \n",
    "    def set_lr(self,lr):\n",
    "        for param_group in self.optimizer.param_groups:\n",
    "            param_group['lr'] = lr\n",
    "    \n",
    "    def on_epoch_begin(self,*args,**kargs):\n",
    "        pass\n",
    "    \n",
    "    def on_epoch_end(self,*args,**kargs):\n",
    "        pass\n",
    "    \n",
    "    def predict(self,ds,batch_size=None,num_workers=8,dl_args={'shuffle':False},return_inds=False,return_true=False,verbose=True,do_eval=True):\n",
    "        device = self.device\n",
    "        if batch_size is not None:\n",
    "            dl_args['batch_size']=batch_size     \n",
    "        dl=D.DataLoader(ds,num_workers=num_workers,**dl_args)\n",
    "        pred_list=[]\n",
    "        inds_list=[]\n",
    "        true_list=[]\n",
    "        if do_eval:\n",
    "            self.model=self.model.eval()\n",
    "        with torch.no_grad():\n",
    "            tk0 = notebook.tqdm(dl) if verbose else dl\n",
    "            for i,batch in enumerate(tk0):\n",
    "                if autocast is None:\n",
    "                    y_pred= self.run_model(self.model,batch) \n",
    "                else:\n",
    "                    with autocast(self.scaler is not None):\n",
    "                        y_pred= self.run_model(self.model,batch) \n",
    "                if return_inds:\n",
    "                    inds_list.append(self.get_inds(batch).to('cpu').numpy())\n",
    "                if return_true:\n",
    "                    yb=self.get_y(batch)\n",
    "                    true_list.append(yb.to('cpu').numpy() if not isinstance(yb,tuple) else\\\n",
    "                                 tuple(y.to('cpu').numpy() for y in yb))\n",
    "                pred_list.append(y_pred.to('cpu').numpy() if not isinstance(y_pred,tuple) else\\\n",
    "                                 tuple(y.to('cpu').numpy() for y in y_pred))\n",
    "        pred = np.concatenate(pred_list,0) if not isinstance(pred_list[0],tuple) else\\\n",
    "                tuple(np.concatenate([p[i] for p in pred_list],0) for i in range(len(pred_list[0])))\n",
    "        out=()\n",
    "        if return_inds:\n",
    "            out=out+(np.concatenate(inds_list,0),)\n",
    "        if return_true:\n",
    "            rt=np.concatenate(true_list,0) if not isinstance(true_list[0],tuple) else\\\n",
    "                    tuple(np.concatenate([p[i] for p in true_list],0) for i in range(len(true_list[0])))\n",
    "            out=out+(rt,)\n",
    "            \n",
    "        return pred if len(out)==0 else (pred,)+out\n",
    "        \n",
    "            \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "var kernel = IPython.notebook.kernel;\n",
       "var thename = window.document.getElementById(\"notebook_name\").innerHTML;\n",
       "var command = \"theNotebook = \" + \"'\"+thename+\"'\";\n",
       "kernel.execute(command);\n",
       "IPython.notebook.save_notebook()\n"
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%javascript\n",
    "var kernel = IPython.notebook.kernel;\n",
    "var thename = window.document.getElementById(\"notebook_name\").innerHTML;\n",
    "var command = \"theNotebook = \" + \"'\"+thename+\"'\";\n",
    "kernel.execute(command);\n",
    "IPython.notebook.save_notebook()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Converted LearnerClass.ipynb to exp/LearnerClass.py\r\n"
     ]
    }
   ],
   "source": [
    "full_notebook_name=theNotebook+'.ipynb'\n",
    "!python notebook2script.py {full_notebook_name}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
