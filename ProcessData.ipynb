{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.6/importlib/_bootstrap.py:219: RuntimeWarning: numpy.ufunc size changed, may indicate binary incompatibility. Expected 192 from C header, got 216 from PyObject\n",
      "  return f(*args, **kwds)\n",
      "/opt/conda/lib/python3.6/importlib/_bootstrap.py:219: RuntimeWarning: numpy.ufunc size changed, may indicate binary incompatibility. Expected 192 from C header, got 216 from PyObject\n",
      "  return f(*args, **kwds)\n",
      "/opt/conda/lib/python3.6/importlib/_bootstrap.py:219: RuntimeWarning: numpy.ufunc size changed, may indicate binary incompatibility. Expected 192 from C header, got 216 from PyObject\n",
      "  return f(*args, **kwds)\n",
      "/opt/conda/lib/python3.6/importlib/_bootstrap.py:219: RuntimeWarning: numpy.ufunc size changed, may indicate binary incompatibility. Expected 192 from C header, got 216 from PyObject\n",
      "  return f(*args, **kwds)\n"
     ]
    }
   ],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(action='once')\n",
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "InteractiveShell.ast_node_interactivity = \"all\"\n",
    "import pickle\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline\n",
    "import matplotlib.pylab as plt\n",
    "import seaborn as sns\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tqdm import notebook\n",
    "from exp.misc import *\n",
    "import torch\n",
    "import PIL.Image\n",
    "import pydicom\n",
    "import cv2\n",
    "from torchvision import transforms\n",
    "import torchvision.transforms.functional as TF\n",
    "from collections import defaultdict\n",
    "import pydicom\n",
    "import io\n",
    "import zipfile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "from torch.utils.data import Dataset\n",
    "class DatasetCat(Dataset):\n",
    "    '''\n",
    "    Concatenate datasets for Pytorch dataloader\n",
    "    The normal pytorch implementation does it only for raws. this is a \"column\" implementation\n",
    "    Arges:\n",
    "        datasets: list of datasets, of the same length\n",
    "    Updated: Yuval 12/10/2019\n",
    "    '''\n",
    "    \n",
    "    def __init__(self,datasets):\n",
    "        '''\n",
    "        Args: datasets - an iterable containing the datasets\n",
    "        '''\n",
    "        super(DatasetCat, self).__init__()\n",
    "        self.datasets=datasets\n",
    "        assert len(self.datasets)>0\n",
    "        for dataset in datasets:\n",
    "            assert len(self.datasets[0])==len(dataset),\"Datasets length should be equal\"\n",
    "            \n",
    "    def __len__(self):\n",
    "        return len(self.datasets[0])\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        outputs = tuple(dataset.__getitem__(idx) for i in self.datasets for dataset in (i if isinstance(i, tuple) else (i,)))\n",
    "        return tuple(output for i in outputs for output in (i if isinstance(i, tuple) else (i,)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "params=json_to_parameters('config.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.6/site-packages/IPython/core/interactiveshell.py:3063: DtypeWarning: Columns (23,49,50) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  interactivity=interactivity, compiler=compiler, result=result)\n"
     ]
    }
   ],
   "source": [
    "train_df=pd.read_csv(params.path.data+'train.csv')\n",
    "df = pd.read_csv(params.path.data+'full_train.csv')\n",
    "# file_handler = zipfile.ZipFile(params.path.data+'train.zip', mode = 'r', allowZip64 = True) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "\n",
    "def create_folds(df,num_folds,SEED,split_col='SeriesInstanceUID',errors=lambda x: x.pxl_min.isna()):\n",
    "    df = df.reset_index(drop=True)\n",
    "    df=df if errors is None else df[~errors(df)]\n",
    "    items=np.sort(df[split_col].unique())\n",
    "    np.random.seed(SEED)\n",
    "    np.random.shuffle(items)\n",
    "    nu=int(np.ceil(items.shape[0]/num_folds))\n",
    "    items_val=[set(items[i*nu:(i+1)*nu]) for i in range(num_folds)]\n",
    "    val_folds=[np.sort(df[df[split_col].isin(items_val[i])].index.values) for i in range(num_folds)]\n",
    "    train_folds=[np.sort(np.setdiff1d(df.index.values,val_folds[i])) for i in range(num_folds)]\n",
    "    return val_folds, train_folds, [np.array(list(s)) for s in items_val]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "from PIL import  ImageDraw\n",
    "import torch\n",
    "\n",
    "def randint(low,high):\n",
    "    return torch.randint(low,high,(1,))[0]\n",
    "\n",
    "def randfloat(low,high):\n",
    "    return torch.rand((1,))[0]*(high-low)+low\n",
    "\n",
    "class CutoutTransform():\n",
    "    def __init__(self,p=0.5,size=0.1,fill=None):\n",
    "        self.p=p\n",
    "        self.size = (size,size) if isinstance(size,float) else size\n",
    "        self.fill = fill\n",
    "    def __call__(self,img):\n",
    "        if torch.rand((1,))<self.p:\n",
    "            s0,s1 = int(img.shape[-2]*randfloat(0,self.size[0])),int(img.shape[-1]*randfloat(0,self.size[1]))\n",
    "            sx=torch.randint(0,img.shape[-2]-s0,(1,))\n",
    "            sy=torch.randint(0,img.shape[-1]-s1,(1,))\n",
    "            img[...,sx:sx+s0,sy:sy+s1]=img.min() if self.fill is None else self.fill\n",
    "        return img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "from skimage import transform as sktransform\n",
    "\n",
    "def np_tensor_transform(img,transform,*args,**kwarg):    \n",
    "    npa = isinstance(img, np.ndarray)\n",
    "    img = img if npa else img.numpy() if len(img.shape)==2 else img.permute(1,2,0).numpy()\n",
    "    img = transform(img,*args,**kwarg)\n",
    "    img = img if npa else torch.tensor(img) if len(img.shape)==2 else torch.tensor(img).permute(2,1,0)\n",
    "    return img\n",
    "\n",
    "def pad_cut(a,plen,dim=0,value=0):\n",
    "    if plen>0:\n",
    "        r=tuple([plen//a.shape[dim]+1]+[1]*(len(a.shape)-1))\n",
    "        return np.concatenate([a,np.moveaxis(np.tile(np.moveaxis(np.ones_like(a),0,dim),r)[:plen],0,dim)*value],dim)\n",
    "    elif plen<0:\n",
    "        return np.moveaxis(np.moveaxis(a,0,dim)[:a.shape[dim]+plen],0,dim)\n",
    "    else:\n",
    "        return a\n",
    "\n",
    "def simple_resize(img,shape,pad_value=0):\n",
    "    shape= (shape,shape) if isinstance(shape,int) else shape\n",
    "    return pad_cut(pad_cut(img,shape[0]-img.shape[0],0,-1000),shape[1]-img.shape[1],1,pad_value)\n",
    "\n",
    "class SimpleResizeTransform():\n",
    "    def __init__(self,*args,**kwargs):\n",
    "        self.args=args\n",
    "        self.kwargs=kwargs\n",
    "    def __call__(self,img):\n",
    "        return np_tensor_transform(img,simple_resize,*self.args,**self.kwargs)\n",
    "\n",
    "def resize(img,shape,anti_aliasing=True):\n",
    "    shape= (shape,shape) if isinstance(shape,int) else shape\n",
    "    return np_tensor_transform(img,sktransform.resize,shape,anti_aliasing=anti_aliasing)\n",
    "\n",
    "class ResizeTransform():\n",
    "    def __init__(self,*args,**kwargs):\n",
    "        self.args=args\n",
    "        self.kwargs=kwargs\n",
    "    def __call__(self,img):\n",
    "        return resize(img,*self.args,**self.kwargs)\n",
    "    \n",
    "def _crop(img,x,y,width,height,const=None):\n",
    "    const = const if const is not None else img.min()\n",
    "    d = len(img.shape)\n",
    "    img = img[:,:,None] if d==2 else img\n",
    "    if width>img.shape[1]:\n",
    "        img=np.concatenate([np.ones((img.shape[0],(width-img.shape[1])//2+1,img.shape[-1]))*const,\n",
    "                            img,\n",
    "                            np.ones((img.shape[0],(width-img.shape[1])//2+1,img.shape[-1]))*const],1)\n",
    "    if height>img.shape[0]:\n",
    "        img=np.concatenate([np.ones(((height-img.shape[0])//2+1,img.shape[1],img.shape[-1]))*const,\n",
    "                            img,\n",
    "                            np.ones(((height-img.shape[0])//2+1,img.shape[1],img.shape[-1]))*const],0)\n",
    "\n",
    "    return img[x:x+width,y:y+height] if d==3 else img[x:x+width,y:y+height,0]\n",
    "\n",
    "def _center_crop(img,width,height,const=None):\n",
    "    return _crop(img,max(0,(img.shape[0]-width)//2),max(0,(img.shape[1]-height)//2),width,height,const)\n",
    "\n",
    "def crop (img,x,y,shape,const=None):\n",
    "    width,height = (shape,shape) if isinstance(shape,int) else shape\n",
    "    return np_tensor_transform(img,_crop,x,y,const)\n",
    "\n",
    "class CropTransform():\n",
    "    def __init__(self,*args,**kwargs):\n",
    "        self.args=args\n",
    "        self.kwargs=kwargs\n",
    "    def __call__(self,img):\n",
    "        return crop(img,*self.args,**self.kwargs)\n",
    "\n",
    "def center_crop (img,shape,const=None):\n",
    "    width,height = (shape,shape) if isinstance(shape,int) else shape\n",
    "    return np_tensor_transform(img,_center_crop,width,height,const)\n",
    "\n",
    "class CenterCropTransform():\n",
    "    def __init__(self,*args,**kwargs):\n",
    "        self.args=args\n",
    "        self.kwargs=kwargs\n",
    "    def __call__(self,img):\n",
    "        return center_crop(img,*self.args,**self.kwargs)\n",
    "\n",
    "def random_resized_crop(img, scale=(0.9, 1.1), ratio=(0.75, 1.3333333333333333)):\n",
    "    shape= img.shape[:2] if isinstance(img, np.ndarray) else img.shape[-2:] \n",
    "    s = randfloat(*scale)\n",
    "    r = randfloat(*ratio) if ratio is not None else 1\n",
    "    return center_crop(resize(img,(int(s*r*shape[0]),int(s/r*shape[1]))),shape)\n",
    "\n",
    "class RandomResizedCropTransform():\n",
    "    def __init__(self,*args,**kwargs):\n",
    "        self.args=args\n",
    "        self.kwargs=kwargs\n",
    "    def __call__(self,img):\n",
    "        return random_resized_crop(img,*self.args,**self.kwargs)\n",
    "\n",
    "def rotate(img,angle,resize=False):\n",
    "    return np_tensor_transform(img,sktransform.rotate , angle, resize=resize, center=None, order=1, \n",
    "                                mode='constant', cval=img.min(), clip=True, preserve_range=False)\n",
    "\n",
    "class RotateTransform():\n",
    "    def __init__(self,*args,**kwargs):\n",
    "        self.args=args\n",
    "        self.kwargs=kwargs\n",
    "    def __call__(self,img):\n",
    "        return rotate(img,*self.args,**self.kwargs)\n",
    "\n",
    "def random_rotate(img,angle,resize=False):\n",
    "    return rotate(img,randfloat(-angle,angle),resize=False)\n",
    "\n",
    "class RandomRotateTransform():\n",
    "    def __init__(self,*args,**kwargs):\n",
    "        self.args=args\n",
    "        self.kwargs=kwargs\n",
    "    def __call__(self,img):\n",
    "        return random_rotate(img,*self.args,**self.kwargs)\n",
    "\n",
    "def _flip(img,axis):\n",
    "    return np.flip(img,axis).copy()\n",
    "\n",
    "def flip(img,axis=1):\n",
    "    return np_tensor_transform(img,_flip,axis=axis)\n",
    "\n",
    "def hflip(img):\n",
    "    return flip(img)\n",
    "    \n",
    "def vflip(img):\n",
    "    return flip(img,axis=0)\n",
    "    \n",
    "def random_flip(img,h=0,v=0):\n",
    "    img = img if randfloat(0,1)>v else vflip(img) \n",
    "    img = img if randfloat(0,1)>h else hflip(img) \n",
    "    return img\n",
    "\n",
    "class RandomFlipTransform():\n",
    "    def __init__(self,*args,**kwargs):\n",
    "        self.args=args\n",
    "        self.kwargs=kwargs\n",
    "    def __call__(self,img):\n",
    "        return random_flip(img,*self.args,**self.kwargs)\n",
    "\n",
    "def random_change_mean_std(img,mean,std):\n",
    "    s=randfloat(-std,std)\n",
    "    s = 1+s if s>=0 else 1/(1-s)\n",
    "    img = img*s + randfloat(-mean,mean)\n",
    "    return img\n",
    "\n",
    "class RandomChangeMeanStdTransform():\n",
    "    def __init__(self,*args,**kwargs):\n",
    "        self.args=args\n",
    "        self.kwargs=kwargs\n",
    "    def __call__(self,img):\n",
    "        return random_change_mean_std(img,*self.args,**self.kwargs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "from multiprocessing import Lock\n",
    "def find_cog(ar,p=0.15):\n",
    "    c=(ar.max()-ar.min())*p+ar.min()\n",
    "    return (ar.mean(),ar.std()) if (ar>c).sum()==0 else (ar[ar>c].mean(),ar[ar>c].std())\n",
    "\n",
    "# def read_image(image_path,images_file):\n",
    "#     with images_file.open(image_path) as zf:\n",
    "#             img_dicom=pydicom.read_file(io.BytesIO(zf.read()))\n",
    "#     img = img_dicom.pixel_array.astype(np.float)\n",
    "#     return img+float(img_dicom.RescaleIntercept) \n",
    "\n",
    "class Singleton(type):\n",
    "    _instances = {}\n",
    "    __singleton_lock = Lock()\n",
    "    def __call__(cls, *args, **kwargs):\n",
    "        with cls.__singleton_lock:\n",
    "            if cls not in cls._instances:\n",
    "                cls._instances[cls] = super(Singleton, cls).__call__(*args, **kwargs)\n",
    "        return cls._instances[cls]\n",
    "\n",
    "\n",
    "# class ImageReader(object, metaclass=Singleton):\n",
    "#     def __init__(self,filepath):\n",
    "#         self.file_handler = zipfile.ZipFile(filepath, mode = 'r', allowZip64 = True) \n",
    "#         self.lock = Lock()\n",
    "#         self.k=0\n",
    "#     def __call__(self,filename):\n",
    "#         with self.lock:\n",
    "#             with self.file_handler.open(filename) as zf:\n",
    "#                 img_dicom=pydicom.read_file(io.BytesIO(zf.read()))\n",
    "#                 img = img_dicom.pixel_array.astype(np.float)+float(img_dicom.RescaleIntercept)\n",
    "#             return img\n",
    "\n",
    "class ImageReader():\n",
    "    def __init__(self,filepath,image_type='pkl'):\n",
    "        self.filepath = filepath\n",
    "        assert image_type in ['pkl','dicom'], f\"image type must be 'jpg' or 'dicom' and not {image_type} \"\n",
    "        self.image_type=image_type\n",
    "    def __call__(self,filename):\n",
    "        if self.image_type=='pkl':\n",
    "            with gzip.open(self.filepath+filename,'rb') as zf:\n",
    "                img=pickle.load(zf).astype(np.float64)\n",
    "        elif self.image_type=='dicom':\n",
    "            img_dicom = pydicom.read_file(self.filepath+filename)\n",
    "            try:\n",
    "                img = img_dicom.pixel_array.astype(np.float)+float(img_dicom.RescaleIntercept)\n",
    "            except Exception as e:\n",
    "                print (filename,e.message, e.args)\n",
    "                img = np.zeros((512,512),dtype=np.float)\n",
    "        else:\n",
    "            raise Exception(\"image type must be 'jpg' or 'dicom'\")\n",
    "        return img\n",
    "\n",
    "\n",
    "\n",
    "class ImageDataset(Dataset):\n",
    "    \n",
    "    def __init__(self,image_reader,df,transform=ResizeTransform((512,512)),file_ext='.pkl',return_inter=False):\n",
    "        super(ImageDataset, self).__init__()\n",
    "        self.image_reader=image_reader\n",
    "        self.df=df\n",
    "        self.names=(df.StudyInstanceUID+'/'+df.SeriesInstanceUID+'/'+df.SOPInstanceUID+file_ext).values\n",
    "        self.return_true='pe_present_on_image' in df.columns\n",
    "        if self.return_true:\n",
    "            self.pe_present_on_image = df.pe_present_on_image.values\n",
    "            self.negative_exam_for_pe=df.negative_exam_for_pe.values\n",
    "            self.qa_motion=df.qa_motion.values\n",
    "            self.qa_contrast = df.qa_contrast.values\n",
    "            self.flow_artifact = df.flow_artifact.values\n",
    "            self.rv_lv_ratio_gte_1 = df.rv_lv_ratio_gte_1.values*df.pe_present_on_image.values\n",
    "            self.rv_lv_ratio_lt_1 = df.rv_lv_ratio_lt_1.values*df.pe_present_on_image.values\n",
    "            self.leftsided_pe = df.leftsided_pe.values*df.pe_present_on_image.values\n",
    "            self.chronic_pe = df.chronic_pe.values*df.pe_present_on_image.values\n",
    "            self.true_filling_defect_not_pe = df.true_filling_defect_not_pe.values\n",
    "            self.rightsided_pe  = df.rightsided_pe.values*df.pe_present_on_image.values\n",
    "            self.acute_and_chronic_pe = df.acute_and_chronic_pe.values*df.pe_present_on_image.values\n",
    "            self.central_pe = df.central_pe.values*df.pe_present_on_image.values\n",
    "            self.indeterminate = df.indeterminate.values\n",
    "        self.rel_slice=df.rel_slice.values\n",
    "        self.transform=transform\n",
    "        self.return_inter=return_inter\n",
    "\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.names)\n",
    "    \n",
    "\n",
    "    def __getitem__(self,idx):\n",
    "        img=self.transform(torch.tensor(self.image_reader(self.names[idx]))[None]).to(dtype=torch.float32)\n",
    "        out = (img,)\n",
    "        if self.return_true:\n",
    "            if not self.return_inter:\n",
    "                out = out + (torch.tensor([  self.pe_present_on_image[idx],\n",
    "                                    self.qa_motion[idx],\n",
    "                                    self.qa_contrast[idx],\n",
    "                                    self.flow_artifact[idx],\n",
    "                                    self.rv_lv_ratio_gte_1[idx],\n",
    "                                    self.rv_lv_ratio_lt_1[idx],\n",
    "                                    self.leftsided_pe[idx],\n",
    "                                    self.chronic_pe[idx],\n",
    "                                    self.rightsided_pe[idx],\n",
    "                                    self.acute_and_chronic_pe[idx],\n",
    "                                    self.central_pe[idx]],dtype=torch.float32),)\n",
    "            else:\n",
    "                out = out + (torch.tensor([  self.pe_present_on_image[idx],\n",
    "                                    self.qa_motion[idx],\n",
    "                                    self.qa_contrast[idx],\n",
    "                                    self.flow_artifact[idx],\n",
    "                                    self.rv_lv_ratio_gte_1[idx],\n",
    "                                    self.rv_lv_ratio_lt_1[idx],\n",
    "                                    self.leftsided_pe[idx],\n",
    "                                    self.chronic_pe[idx],\n",
    "                                    self.rightsided_pe[idx],\n",
    "                                    self.acute_and_chronic_pe[idx],\n",
    "                                    self.central_pe[idx],\n",
    "                                    self.indeterminate[idx]],dtype=torch.float32),)\n",
    "            \n",
    "\n",
    "        out =out + (self.rel_slice[idx],)\n",
    "        return  out\n",
    "                \n",
    "\n",
    "            \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Negative for PE\t0.0736196319\n",
    "Indeterminate\t0.09202453988\n",
    "Chronic\t0.1042944785\n",
    "Acute & Chronic\t0.1042944785\n",
    "Central PE\t0.1877300613\n",
    "Left PE\t0.06257668712\n",
    "Right PE\t0.06257668712\n",
    "RV/LV Ratio >= 1\t0.2346625767\n",
    "RV/LV Ratio < 1\t0.0782208589\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "n=np.array([0.5,0.09202453988/2,\n",
    " 0.09202453988/2,\n",
    " 0.09202453988,\n",
    " 0.2346625767,\n",
    " 0.0782208589,\n",
    " 0.06257668712,\n",
    " 0.1042944785,\n",
    " 0.06257668712,\n",
    " 0.1042944785,\n",
    "           0.1877300613])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "m=n/n.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.32929293, 0.03030303, 0.03030303, 0.06060606, 0.15454545,\n",
       "       0.05151515, 0.04121212, 0.06868687, 0.04121212, 0.06868687,\n",
       "       0.12363636])"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.tensor(df.true_filling_defect_not_pe,dtype=torch.float32),\n",
    "                                          torch.tensor(df.qa_motion,dtype=torch.float32),\n",
    "                                          torch.tensor(df.qa_contrast,dtype=torch.float32),\n",
    "                                          torch.tensor(df.flow_artifact,dtype=torch.float32),\n",
    "                                          torch.tensor(df.rv_lv_ratio_gte_1,dtype=torch.float32),\n",
    "                                          torch.tensor(df.rv_lv_ratio_lt_1,dtype=torch.float32),\n",
    "                                          torch.tensor(df.leftsided_pe,dtype=torch.float32),\n",
    "                                          torch.tensor(df.chronic_pe,dtype=torch.float32),\n",
    "                                          torch.tensor(df.negative_exam_for_pe,dtype=torch.float32),\n",
    "                                          torch.tensor(df.rightsided_pe,dtype=torch.float32),\n",
    "                                          torch.tensor(df.acute_and_chronic_pe,dtype=torch.float32),\n",
    "                                          torch.tensor(df.central_pe,dtype=torch.float32),\n",
    "                                          torch.tensor(df.indeterminate,dtype=torch.float32)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Label\tWeight\n",
    "Negative for PE\t0.0736196319\n",
    "Indeterminate\t0.09202453988\n",
    "Chronic\t0.1042944785\n",
    "Acute & Chronic\t0.1042944785\n",
    "Central PE\t0.1877300613\n",
    "Left PE\t0.06257668712\n",
    "Right PE\t0.06257668712\n",
    "RV/LV Ratio >= 1\t0.2346625767\n",
    "RV/LV Ratio < 1\t0.0782208589\n",
    "0.2346625767,\n",
    "                      0.0782208589,\n",
    "                      0.06257668712,\n",
    "                      0.1042944785,\n",
    "                      0.0736196319,\n",
    "                      0.06257668712,\n",
    "                      0.1042944785,\n",
    "                      0.1877300613,\n",
    "                      0.09202453988\n",
    "                                          torch.tensor(df.rv_lv_ratio_gte_1,dtype=torch.float32),\n",
    "                                          torch.tensor(df.rv_lv_ratio_lt_1,dtype=torch.float32),\n",
    "                                          torch.tensor(df.leftsided_pe,dtype=torch.float32),\n",
    "                                          torch.tensor(df.chronic_pe,dtype=torch.float32),\n",
    "                                          torch.tensor(df.negative_exam_for_pe,dtype=torch.float32),\n",
    "                                          torch.tensor(df.rightsided_pe,dtype=torch.float32),\n",
    "                                          torch.tensor(df.acute_and_chronic_pe,dtype=torch.float32),\n",
    "                                          torch.tensor(df.central_pe,dtype=torch.float32),\n",
    "                                          torch.tensor(df.indeterminate,dtype=torch.float32)],1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "OutputMap={'dummy0':0,\n",
    "           'dummy1':1,\n",
    "           'dummy2':2,\n",
    "           'dummy3':3,\n",
    "           'true_filling_defect_not_pe':0,\n",
    "           'qa_motion':1,\n",
    "           'qa_contrast':2,\n",
    "           'flow_artifact':3,\n",
    "           'rv_lv_ratio_gte_1':4,\n",
    "           'rv_lv_ratio_lt_1':5,\n",
    "           'leftsided_pe':6,\n",
    "           'chronic_pe':7,\n",
    "           'negative_exam_for_pe':8,\n",
    "           'rightsided_pe':9,\n",
    "           'acute_and_chronic_pe':10,\n",
    "           'central_pe':11,\n",
    "           'indeterminate':12}\n",
    "\n",
    "def fair_split(a,max_len):\n",
    "    k=int(np.ceil(len(a)/max_len))\n",
    "    return [a[i::k] for i in range(k)]\n",
    "\n",
    "def pad(a,plen,dim=0,value=0):\n",
    "    r=tuple([plen//a.shape[dim]+1]+[1]*(len(a.shape)-1))\n",
    "    return torch.cat([a,torch.ones_like(a).transpose(0,dim).repeat(r)[:plen].transpose(0,dim)*value],dim)\n",
    "\n",
    "MAX_INSTANCE=3000\n",
    "class PatientFeaturesDataset(Dataset):\n",
    "    \n",
    "    def __init__(self,features,df,series_ids,max_len=250,rand_split=True,rep=1,new_z=False,fnoise=0.,extra=None):\n",
    "        super(PatientFeaturesDataset, self).__init__()\n",
    "        self.df=df\n",
    "        self.features=features\n",
    "        self.max_len=max_len\n",
    "        self.series_ids=series_ids\n",
    "        self.rand_split=rand_split\n",
    "        self.subset = df.SeriesInstanceUID.isin(self.series_ids).values\n",
    "        self.rep=rep\n",
    "        self.rel_slice=torch.tensor(df.rel_slice.values if not new_z else df.rel_z,dtype=torch.float32)  \n",
    "        self.instance_number=torch.tensor(np.clip(df.instance_number.values if not new_z else df.new_rel_slice,\n",
    "                                                                                      1,MAX_INSTANCE-1),dtype=torch.long)   \n",
    "        self.reset()\n",
    "        self.fnoise=fnoise\n",
    "        self.return_true='pe_present_on_image' in df.columns\n",
    "        self.extra = None if extra is None else torch.tensor(df[extra['col']].values/extra['norm'],dtype=torch.float32)\n",
    "        self.extra_n = None if extra is None else extra['noise']\n",
    "        if self.return_true:\n",
    "            self.pe_present_on_image = torch.tensor(df.pe_present_on_image.values,dtype=torch.float32)\n",
    "            self.series_values=torch.stack([torch.tensor(df.true_filling_defect_not_pe,dtype=torch.float32),\n",
    "                                          torch.tensor(df.qa_motion,dtype=torch.float32),\n",
    "                                          torch.tensor(df.qa_contrast,dtype=torch.float32),\n",
    "                                          torch.tensor(df.flow_artifact,dtype=torch.float32),\n",
    "                                          torch.tensor(df.rv_lv_ratio_gte_1,dtype=torch.float32),\n",
    "                                          torch.tensor(df.rv_lv_ratio_lt_1,dtype=torch.float32),\n",
    "                                          torch.tensor(df.leftsided_pe,dtype=torch.float32),\n",
    "                                          torch.tensor(df.chronic_pe,dtype=torch.float32),\n",
    "                                          torch.tensor(df.negative_exam_for_pe,dtype=torch.float32),\n",
    "                                          torch.tensor(df.rightsided_pe,dtype=torch.float32),\n",
    "                                          torch.tensor(df.acute_and_chronic_pe,dtype=torch.float32),\n",
    "                                          torch.tensor(df.central_pe,dtype=torch.float32),\n",
    "                                          torch.tensor(df.indeterminate,dtype=torch.float32)],1)\n",
    "\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.idx_list)\n",
    "    \n",
    "    def reset(self):\n",
    "        gp=self.df[self.subset].groupby('SeriesInstanceUID')\n",
    "        self.idx_list=[]\n",
    "        for j in range(self.rep):\n",
    "            for g in gp.groups.items():\n",
    "                idxs=g[1].values\n",
    "                if self.rand_split:\n",
    "                    idxs=idxs[torch.randperm(len(idxs))]\n",
    "                self.idx_list.extend(fair_split(idxs,self.max_len-1))\n",
    "        \n",
    "            \n",
    "        \n",
    "    def __getitem__(self,idx):\n",
    "        idxs=self.idx_list[idx]\n",
    "        idxs=idxs[np.argsort(self.instance_number[idxs])]\n",
    "        a= torch.randint(0,self.features.shape[0],(len(idxs),))\n",
    "        plen=len(idxs)\n",
    "        out = (pad(self.features[a,idxs]*(1+self.fnoise*torch.randn_like(self.features[a,idxs])),self.max_len-plen,dim=0,value=0),)\n",
    "        out = out if self.extra is None else out + (pad(self.extra[idxs]+self.extra_n*torch.randn(1,),self.max_len-plen,dim=0,value=-1),)\n",
    "        out = out + ( pad(self.rel_slice[idxs],self.max_len-plen,dim=0,value=-1),\\\n",
    "                      pad(self.instance_number[idxs],self.max_len-plen,dim=0,value=0),)\n",
    "        if self.return_true:\n",
    "            out = out + (pad(self.pe_present_on_image[idxs],self.max_len-plen,dim=0,value=-1),self.series_values[idxs[0]],)\n",
    "        out=out+(pad(torch.tensor(idxs,dtype=torch.long),self.max_len-plen,dim=0,value=-1),)\n",
    "        return out\n",
    "        \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "var kernel = IPython.notebook.kernel;\n",
       "var thename = window.document.getElementById(\"notebook_name\").innerHTML;\n",
       "var command = \"theNotebook = \" + \"'\"+thename+\"'\";\n",
       "kernel.execute(command);\n",
       "IPython.notebook.save_notebook()\n"
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%javascript\n",
    "var kernel = IPython.notebook.kernel;\n",
    "var thename = window.document.getElementById(\"notebook_name\").innerHTML;\n",
    "var command = \"theNotebook = \" + \"'\"+thename+\"'\";\n",
    "kernel.execute(command);\n",
    "IPython.notebook.save_notebook()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Converted ProcessData.ipynb to exp/ProcessData.py\r\n"
     ]
    }
   ],
   "source": [
    "full_notebook_name=theNotebook+'.ipynb'\n",
    "!python notebook2script.py {full_notebook_name}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
