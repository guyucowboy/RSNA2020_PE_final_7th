{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.6/importlib/_bootstrap.py:219: RuntimeWarning: numpy.ufunc size changed, may indicate binary incompatibility. Expected 192 from C header, got 216 from PyObject\n",
      "  return f(*args, **kwds)\n",
      "/opt/conda/lib/python3.6/importlib/_bootstrap.py:219: RuntimeWarning: numpy.ufunc size changed, may indicate binary incompatibility. Expected 192 from C header, got 216 from PyObject\n",
      "  return f(*args, **kwds)\n",
      "/opt/conda/lib/python3.6/importlib/_bootstrap.py:219: RuntimeWarning: numpy.ufunc size changed, may indicate binary incompatibility. Expected 192 from C header, got 216 from PyObject\n",
      "  return f(*args, **kwds)\n",
      "/opt/conda/lib/python3.6/importlib/_bootstrap.py:219: RuntimeWarning: numpy.ufunc size changed, may indicate binary incompatibility. Expected 192 from C header, got 216 from PyObject\n",
      "  return f(*args, **kwds)\n",
      "/opt/conda/lib/python3.6/importlib/_bootstrap.py:219: RuntimeWarning: numpy.ufunc size changed, may indicate binary incompatibility. Expected 192 from C header, got 216 from PyObject\n",
      "  return f(*args, **kwds)\n",
      "/opt/conda/lib/python3.6/importlib/_bootstrap.py:219: RuntimeWarning: numpy.ufunc size changed, may indicate binary incompatibility. Expected 192 from C header, got 216 from PyObject\n",
      "  return f(*args, **kwds)\n",
      "/opt/conda/lib/python3.6/importlib/_bootstrap.py:219: RuntimeWarning: numpy.ufunc size changed, may indicate binary incompatibility. Expected 192 from C header, got 216 from PyObject\n",
      "  return f(*args, **kwds)\n",
      "/opt/conda/lib/python3.6/importlib/_bootstrap.py:219: RuntimeWarning: numpy.ufunc size changed, may indicate binary incompatibility. Expected 192 from C header, got 216 from PyObject\n",
      "  return f(*args, **kwds)\n"
     ]
    }
   ],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(action='once')\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pylab as plt\n",
    "import seaborn as sns\n",
    "import datetime\n",
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "InteractiveShell.ast_node_interactivity = \"all\"\n",
    "import pickle\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline\n",
    "from exp.misc import *\n",
    "from exp.ProcessData import *\n",
    "from exp.PytorchModels import *\n",
    "from exp.LearnerClass import *\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.utils.data as D\n",
    "import torch.nn.functional as F\n",
    "import copy\n",
    "from torchvision import transforms\n",
    "import PIL.Image\n",
    "from sklearn.metrics import roc_auc_score\n",
    "import torchvision.transforms.functional as TF\n",
    "from types import MethodType\n",
    "import sandesh\n",
    "import pydicom"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "params=json_to_parameters('config.json')\n",
    "num_folds=5\n",
    "SEED=220\n",
    "device = device_by_name('Tesla') # set to GPU name or part of GPU name\n",
    "model_type='tf_efficientnet_b5_ns' # set model type\n",
    "loss_int = True # True to use intermidiate in the loss function\n",
    "pool=True # True - use pooling, False - use linear layer\n",
    "dropout=0.5\n",
    "wso_requires_grad=True # True - use WSO, False - static windows\n",
    "folds=[1]\n",
    "seed_add=22222\n",
    "model_version='pdint' #set version name\n",
    "num_tta=0 # number of augmented features matrixes - 0 means ther will be only 1 an aungemted feature vector per image \n",
    "image_type='pkl' #if you unziped train.zip, use 'dicom'\n",
    "torch.cuda.set_device(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.6/site-packages/IPython/core/interactiveshell.py:3063: DtypeWarning: Columns (23,49,50) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  interactivity=interactivity, compiler=compiler, result=result)\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv(params.path.data+'full_train.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if loss_int:\n",
    "    WEIGHTS=torch.tensor([0.32929293, 0.01030303, 0.01030303, 0.06060606, 0.15454545,\n",
    "           0.05151515, 0.04121212, 0.06868687, 0.04121212, 0.06868687,\n",
    "           0.12363636,0.0404])\n",
    "    output_size=12\n",
    "else:\n",
    "    WEIGHTS=torch.tensor([0.32929293, 0.03030303, 0.03030303, 0.06060606, 0.15454545,\n",
    "           0.05151515, 0.04121212, 0.06868687, 0.04121212, 0.06868687,\n",
    "           0.12363636])\n",
    "    output_size=11\n",
    "\n",
    "def my_metric(y_pred,y_true,gamma=[0.,0.]):\n",
    "#     loss=F.binary_cross_entropy_with_logits(torch.tensor(y_pred,dtype=torch.float32),torch.tensor(y_true,dtype=torch.float32),WEIGHTS).detach().item()\n",
    "    loss=BinaryFocalLoss(gamma=gamma,weights=WEIGHTS)(torch.tensor(y_pred,dtype=torch.float32),torch.tensor(y_true,dtype=torch.float32)).detach().item()\n",
    "    return_dict={'metric':loss}\n",
    "    return return_dict\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transform=transforms.Compose([RandomResizedCropTransform(scale=(0.7, 1.3), ratio=(0.7, 1.3)),\n",
    "                              RotateTransform(45),\n",
    "                              RandomFlipTransform(0.5,0.5),\n",
    "                              RandomChangeMeanStdTransform(30,1.),\n",
    "                              CutoutTransform(0.5,0.2),\n",
    "                              CutoutTransform(0.25,0.3),\n",
    "                              ResizeTransform(512,512)])\n",
    "\n",
    "transform_val=transforms.Compose([SimpleResizeTransform((512,512),-1024)])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "epoch_in_rep=6\n",
    "reps =1\n",
    "num_epochs=epoch_in_rep*reps\n",
    "batch_size=24\n",
    "reps_lr=[3e-4*batch_size/32,1e-4*batch_size/32,0.3e-4*batch_size/32]\n",
    "pos_mul=1\n",
    "epoch_mul=1\n",
    "epoch_part=0.15\n",
    "gamma=[0.,0.]\n",
    "image_reader=ImageReader(params.path.train,image_type=image_type)\n",
    "for SEED in [220]:\n",
    "    val_folds, train_folds, patients_val = create_folds(df,num_folds,SEED)\n",
    "    for fold in folds: #range(num_folds):\n",
    "        torch.manual_seed(SEED+fold+seed_add)\n",
    "        np.random.seed(SEED+fold+seed_add)\n",
    "        torch.backends.cudnn.deterministic = True\n",
    "        torch.backends.cudnn.benchmark = False\n",
    "        validate_ds=D.Subset(ImageDataset(image_reader,df,transform=transform_val,return_inter=True),val_folds[fold])\n",
    "        train_ds=D.Subset(ImageDataset(image_reader,df,transform=transform,return_inter=True),train_folds[fold])\n",
    "        epoch_size=int(len(train_ds)*epoch_part)\n",
    "        \n",
    "        model = get_model(model_type,output_size=output_size, feature_size =256,amp=True,pool=pool,\n",
    "                          dropout=dropout,wso_requires_grad=wso_requires_grad).to(device)\n",
    "        name=params.model_format.format(model_type,f'image_{SEED}',model_version,fold)\n",
    "        my_loss=BinaryFocalLoss(gamma=gamma,weights=WEIGHTS.to(device)) \n",
    "        learner = Learner(model,None,loss_func=my_loss,name=name,scheduler=None,device=device)\n",
    "        learner.metric=my_metric\n",
    "        sweights=np.where(train_ds.dataset.pe_present_on_image[train_folds[fold]],\n",
    "                  train_ds.dataset.pe_present_on_image[train_folds[fold]],\n",
    "                  np.sin(train_ds.dataset.rel_slice[train_folds[fold]]*np.pi))+0.2\n",
    "\n",
    "        learner.sampler=D.WeightedRandomSampler(sweights,epoch_size, replacement=True)\n",
    "        learner.optimizer = torch.optim.Adam(learner.model.parameters(), lr=1e-4)\n",
    "        learner.init_amp(do_autocast=False)\n",
    "        def new_get_y(self,batch):\n",
    "            return batch[1]\n",
    "        def new_get_x(self,batch):\n",
    "            return batch[:1] \n",
    "        learner.get_y=MethodType(new_get_y, learner)\n",
    "        learner.get_x=MethodType(new_get_x, learner)\n",
    "#        learner.load_checkpoint(params.path.models)\n",
    "\n",
    "\n",
    "        train_dl_args={'shuffle':False,'batch_size':batch_size,'sampler':learner.sampler}\n",
    "        val_dl_args={'shuffle':True}\n",
    "    \n",
    "        for t in range(reps):\n",
    "            learner.scheduler = torch.optim.lr_scheduler.OneCycleLR(learner.optimizer, pct_start=0.01,final_div_factor= 10,\n",
    "                                                                    max_lr=reps_lr[t], steps_per_epoch=epoch_size//batch_size+1, \n",
    "                                                                    epochs=num_epochs//reps)\n",
    "\n",
    "            learner.fit(num_epochs//reps,train_ds,validate_ds,batch_size=batch_size,eval_batch=batch_size,path=params.path.models,\n",
    "                        train_dl_args=train_dl_args,val_dl_args=val_dl_args,num_workers=12)\n",
    "        sandesh.send({'name':learner.name,'best_metric':learner.best_metric})     \n",
    "        learner.save_model(params.path.models)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calculate features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds0=ImageDataset(image_reader,df,transform=transform_val)\n",
    "ds=ImageDataset(image_reader,df,transform=transform)\n",
    "learner.model.last_linear=Noop()\n",
    "featuress=[learner.predict(ds0,batch_size=64,num_workers=20,do_eval=True)]\n",
    "#         featuress=[]\n",
    "sandesh.send({'name':f'finished 1st {SEED} {fold}'})\n",
    "for i in notebook.tqdm(range(num_tta)):\n",
    "#                 learner.model=learner.model.train()\n",
    "    features=learner.predict(ds,batch_size=64,num_workers=12,do_eval=True)\n",
    "    featuress.append(features)\n",
    "    sandesh.send({'name':f'finished {i+1} {SEED} {fold}'})\n",
    "\n",
    "features=np.stack(featuress,0)\n",
    "with open(params.path.features+(name.split('.')[0]+'.pkl'),'wb') as f:\n",
    "    pickle.dump(features,f,protocol=4)\n",
    "sandesh.send({'name':f'saved {features.shape} {SEED} {fold}'})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
