{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.6/importlib/_bootstrap.py:219: RuntimeWarning: numpy.ufunc size changed, may indicate binary incompatibility. Expected 192 from C header, got 216 from PyObject\n",
      "  return f(*args, **kwds)\n",
      "/opt/conda/lib/python3.6/importlib/_bootstrap.py:219: RuntimeWarning: numpy.ufunc size changed, may indicate binary incompatibility. Expected 192 from C header, got 216 from PyObject\n",
      "  return f(*args, **kwds)\n",
      "/opt/conda/lib/python3.6/importlib/_bootstrap.py:219: RuntimeWarning: numpy.ufunc size changed, may indicate binary incompatibility. Expected 192 from C header, got 216 from PyObject\n",
      "  return f(*args, **kwds)\n",
      "/opt/conda/lib/python3.6/importlib/_bootstrap.py:219: RuntimeWarning: numpy.ufunc size changed, may indicate binary incompatibility. Expected 192 from C header, got 216 from PyObject\n",
      "  return f(*args, **kwds)\n",
      "/opt/conda/lib/python3.6/importlib/_bootstrap.py:219: RuntimeWarning: numpy.ufunc size changed, may indicate binary incompatibility. Expected 192 from C header, got 216 from PyObject\n",
      "  return f(*args, **kwds)\n",
      "/opt/conda/lib/python3.6/importlib/_bootstrap.py:219: RuntimeWarning: numpy.ufunc size changed, may indicate binary incompatibility. Expected 192 from C header, got 216 from PyObject\n",
      "  return f(*args, **kwds)\n",
      "/opt/conda/lib/python3.6/importlib/_bootstrap.py:219: RuntimeWarning: numpy.ufunc size changed, may indicate binary incompatibility. Expected 192 from C header, got 216 from PyObject\n",
      "  return f(*args, **kwds)\n",
      "/opt/conda/lib/python3.6/importlib/_bootstrap.py:219: RuntimeWarning: numpy.ufunc size changed, may indicate binary incompatibility. Expected 192 from C header, got 216 from PyObject\n",
      "  return f(*args, **kwds)\n"
     ]
    }
   ],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(action='once')\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pylab as plt\n",
    "import seaborn as sns\n",
    "import datetime\n",
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "InteractiveShell.ast_node_interactivity = \"all\"\n",
    "import pickle\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline\n",
    "from exp.misc import *\n",
    "from exp.ProcessData import *\n",
    "from exp.PytorchModels import *\n",
    "from exp.LearnerClass import *\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.utils.data as D\n",
    "import torch.nn.functional as F\n",
    "import copy\n",
    "from torchvision import transforms\n",
    "import PIL.Image\n",
    "from sklearn.metrics import roc_auc_score\n",
    "import torchvision.transforms.functional as TF\n",
    "from types import MethodType\n",
    "import sandesh\n",
    "import pydicom"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "params=json_to_parameters('config.json')\n",
    "num_folds=5\n",
    "SEED=220\n",
    "device = device_by_name('Tesla')\n",
    "\n",
    "torch.cuda.set_device(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.6/site-packages/IPython/core/interactiveshell.py:3063: DtypeWarning: Columns (23,49,50) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  interactivity=interactivity, compiler=compiler, result=result)\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv(params.path.data+'full_train.csv')\n",
    "# file_handler = zipfile.ZipFile(params.path.data+'train.zip', mode = 'r', allowZip64 = True) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# class MyLoss():\n",
    "#     def __init__(self,weight):\n",
    "#         self.weight=weight\n",
    "#     def __call__(self,y_pred,y_true):\n",
    "        \n",
    "#         return loss\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "WEIGHTS=torch.tensor([0.32929293, 0.01030303, 0.01030303, 0.06060606, 0.15454545,\n",
    "           0.05151515, 0.04121212, 0.06868687, 0.04121212, 0.06868687,\n",
    "           0.12363636,0.0404])\n",
    "# WEIGHTS=WEIGHTS/WEIGHTS.mean()\n",
    "def my_metric(y_pred,y_true,gamma=[0.,0.]):\n",
    "#     loss=F.binary_cross_entropy_with_logits(torch.tensor(y_pred,dtype=torch.float32),torch.tensor(y_true,dtype=torch.float32),WEIGHTS).detach().item()\n",
    "    loss=BinaryFocalLoss(gamma=gamma,weights=WEIGHTS)(torch.tensor(y_pred,dtype=torch.float32),torch.tensor(y_true,dtype=torch.float32)).detach().item()\n",
    "    return_dict={'metric':loss}\n",
    "    return return_dict\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "transform=transforms.Compose([RandomResizedCropTransform(scale=(0.7, 1.3), ratio=(0.7, 1.3)),\n",
    "                              RotateTransform(45),\n",
    "                              RandomFlipTransform(0.5,0.5),\n",
    "                              RandomChangeMeanStdTransform(30,1.),\n",
    "                              CutoutTransform(0.5,0.2),\n",
    "                              CutoutTransform(0.25,0.3),\n",
    "                              ResizeTransform(512,512)])\n",
    "\n",
    "transform_val=transforms.Compose([SimpleResizeTransform((512,512),-1024)])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x7f6a7231c3c0>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading: \"http://data.lip6.fr/cadene/pretrainedmodels/se_resnext101_32x4d-3b2fe3d8.pth\" to /root/.cache/torch/hub/checkpoints/se_resnext101_32x4d-3b2fe3d8.pth\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b4024c3e72ba4fea9ada6a5bd73f30de",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=196466866.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dd646a98f8f04be9b05f5c42ac28e904",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=6.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7af0264844244e57bf151b384d017219",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=8962.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "494a0315f0864301a59b218fe55a0f70",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=14866.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "273393ea186344298556ae7d480d2a80",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=8962.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "99648cd9b41244d480e840da0b9f0c7c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=14866.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "722ae7dd814046ac931d712cfd7b93c6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=8962.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8708d6bd18104189b1d9fbfad3320a04",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=14866.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "af4d546809834d998bb499ff16c6e4ac",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=8962.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "468124be2cdb49bc848241964807f0d3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=14866.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4c18425032f0423ca69ef64dfdcbc4d4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=8962.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "326c1ac074334e72b683242615f41f77",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=14866.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4dd5f487b01b4ae896684983c700c42e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=8962.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9d17268984bd48e99b363ef4f7f21ab1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=14866.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "best metric: 0.006834980100393295\n"
     ]
    }
   ],
   "source": [
    "epoch_in_rep=6\n",
    "reps =1\n",
    "num_epochs=epoch_in_rep*reps\n",
    "batch_size=24\n",
    "reps_lr=[3e-4*batch_size/32,1e-4*batch_size/32,0.3e-4*batch_size/32]\n",
    "pos_mul=1\n",
    "epoch_mul=1\n",
    "epoch_part=0.15\n",
    "# val_epoch_part=0.2\n",
    "gamma=[0.,0.]\n",
    "image_reader=ImageReader(params.path.train)\n",
    "for SEED in [220]: #220 4356,,\n",
    "    val_folds, train_folds, patients_val = create_folds(df,num_folds,SEED)\n",
    "#    val_folds=[np.intersect1d(np.where(~train_df.patient_id.isna())[0],val_fold) for val_fold in val_folds]\n",
    "    for fold in [1]: #range(num_folds):\n",
    "        torch.manual_seed(SEED+fold+22222)\n",
    "        np.random.seed(SEED+fold+22222)\n",
    "        torch.backends.cudnn.deterministic = True\n",
    "        torch.backends.cudnn.benchmark = False\n",
    "        validate_ds=D.Subset(ImageDataset(image_reader,df,transform=transform_val,return_inter=True),val_folds[fold])\n",
    "        train_ds=D.Subset(ImageDataset(image_reader,df,transform=transform,return_inter=True),train_folds[fold])\n",
    "        epoch_size=int(len(train_ds)*epoch_part)\n",
    "        model_type='se_resnext101_32x4d'\n",
    "        model = get_model(model_type,output_size=12, feature_size =256,amp=True,pool=True,dropout=0.5,wso_requires_grad=True).to(device)\n",
    "        name=params.model_format.format(model_type,f'image_{SEED}','pdint',fold)\n",
    "        my_loss=BinaryFocalLoss(gamma=gamma,weights=WEIGHTS.to(device)) #nn.BCEWithLogitsLoss(WEIGHTS.to(device))\n",
    "        learner = Learner(model,None,loss_func=my_loss,name=name,scheduler=None,device=device)\n",
    "        learner.metric=my_metric\n",
    "        sweights=np.where(train_ds.dataset.pe_present_on_image[train_folds[fold]],\n",
    "                  train_ds.dataset.pe_present_on_image[train_folds[fold]],\n",
    "                  np.sin(train_ds.dataset.rel_slice[train_folds[fold]]*np.pi))+0.2\n",
    "#         sweights=np.sin(train_ds.dataset.rel_slice[train_folds[fold]]*np.pi)+0.2\n",
    "        learner.sampler=D.WeightedRandomSampler(sweights,epoch_size, replacement=True)\n",
    "#         val_sweights=np.where(validate_ds.dataset.pe_present_on_image[val_folds[fold]],\n",
    "#                   validate_ds.dataset.pe_present_on_image[val_folds[fold]]*4,\n",
    "#                   0.2+np.sin(validate_ds.dataset.rel_slice[val_folds[fold]]*np.pi))\n",
    "#         learner.val_sampler=D.WeightedRandomSampler(val_sweights,int(len(validate_ds)*val_epoch_part), replacement=False)\n",
    "\n",
    "#        learner.load_model(params.path.models)\n",
    "        learner.optimizer = torch.optim.Adam(learner.model.parameters(), lr=1e-4)\n",
    "        learner.init_amp(do_autocast=False)\n",
    "        def new_get_y(self,batch):\n",
    "            return batch[1]\n",
    "        def new_get_x(self,batch):\n",
    "            return batch[:1] \n",
    "        learner.get_y=MethodType(new_get_y, learner)\n",
    "        learner.get_x=MethodType(new_get_x, learner)\n",
    "#        learner.load_checkpoint(params.path.models)\n",
    "\n",
    "\n",
    "        train_dl_args={'shuffle':False,'batch_size':batch_size,'sampler':learner.sampler}\n",
    "        val_dl_args={'shuffle':True}\n",
    "    \n",
    "        for t in range(reps):\n",
    "            learner.scheduler = torch.optim.lr_scheduler.OneCycleLR(learner.optimizer, pct_start=0.01,final_div_factor= 10,\n",
    "                                                                    max_lr=reps_lr[t], steps_per_epoch=epoch_size//batch_size+1, \n",
    "                                                                    epochs=num_epochs//reps)\n",
    "\n",
    "            learner.fit(num_epochs//reps,train_ds,validate_ds,batch_size=batch_size,eval_batch=batch_size,path=params.path.models,\n",
    "                        train_dl_args=train_dl_args,val_dl_args=val_dl_args,num_workers=12)\n",
    "        sandesh.send({'name':learner.name,'best_metric':learner.best_metric})     \n",
    "        learner.save_model(params.path.models)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# learner.model.load_state_dict(learner.best_model)\n",
    "# learner.save_model(params.path.models)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "42b7304233084ccaa93ba17fcfff12b2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=27979.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fcc69f4ebf7a460bb104d0e37efe6729",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', max=1.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "ds0=ImageDataset(image_reader,df,transform=transform_val)\n",
    "ds=ImageDataset(image_reader,df,transform=transform)\n",
    "learner.model.last_linear=Noop()\n",
    "featuress=[learner.predict(ds0,batch_size=64,num_workers=20,do_eval=True)]\n",
    "#         featuress=[]\n",
    "sandesh.send({'name':f'finished 1st {SEED} {fold}'})\n",
    "for i in notebook.tqdm(range(0)):\n",
    "#                 learner.model=learner.model.train()\n",
    "    features=learner.predict(ds,batch_size=64,num_workers=12,do_eval=True)\n",
    "    featuress.append(features)\n",
    "    sandesh.send({'name':f'finished {i+1} {SEED} {fold}'})\n",
    "\n",
    "features=np.stack(featuress,0)\n",
    "with open(params.path.features+(name.split('.')[0]+'.pkl'),'wb') as f:\n",
    "    pickle.dump(features,f,protocol=4)\n",
    "sandesh.send({'name':f'saved {features.shape} {SEED} {fold}'})\n"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "scrolled": true
   },
   "source": [
    "epoch_in_rep=6\n",
    "reps =1\n",
    "num_epochs=epoch_in_rep*reps\n",
    "batch_size=24\n",
    "reps_lr=[3e-4*batch_size/32,1e-4*batch_size/32,0.3e-4*batch_size/32]\n",
    "pos_mul=1\n",
    "epoch_mul=1\n",
    "epoch_part=0.15\n",
    "# val_epoch_part=0.2\n",
    "gamma=[0.,0.]\n",
    "image_reader=ImageReader(params.path.train)\n",
    "for SEED in [220]: #220 4356,,\n",
    "    val_folds, train_folds, patients_val = create_folds(df,num_folds,SEED)\n",
    "#    val_folds=[np.intersect1d(np.where(~train_df.patient_id.isna())[0],val_fold) for val_fold in val_folds]\n",
    "    for fold in [2]: #range(num_folds):\n",
    "        torch.manual_seed(SEED+fold+2222)\n",
    "        np.random.seed(SEED+fold+2222)\n",
    "        torch.backends.cudnn.deterministic = True\n",
    "        torch.backends.cudnn.benchmark = False\n",
    "        validate_ds=D.Subset(ImageDataset(image_reader,df,transform=transform_val,return_inter=True),val_folds[fold])\n",
    "        train_ds=D.Subset(ImageDataset(image_reader,df,transform=transform,return_inter=True),train_folds[fold])\n",
    "        epoch_size=int(len(train_ds)*epoch_part)\n",
    "        model_type='tf_efficientnet_b6_ns'\n",
    "        model = get_model(model_type,output_size=12, feature_size =256,amp=True,pool=True,dropout=0.5,wso_requires_grad=True).to(device)\n",
    "        name=params.model_format.format(model_type,f'image_{SEED}','pdint',fold)\n",
    "        my_loss=BinaryFocalLoss(gamma=gamma,weights=WEIGHTS.to(device)) #nn.BCEWithLogitsLoss(WEIGHTS.to(device))\n",
    "        learner = Learner(model,None,loss_func=my_loss,name=name,scheduler=None,device=device)\n",
    "        learner.metric=my_metric\n",
    "        sweights=np.where(train_ds.dataset.pe_present_on_image[train_folds[fold]],\n",
    "                  train_ds.dataset.pe_present_on_image[train_folds[fold]],\n",
    "                  np.sin(train_ds.dataset.rel_slice[train_folds[fold]]*np.pi))+0.2\n",
    "#         sweights=np.sin(train_ds.dataset.rel_slice[train_folds[fold]]*np.pi)+0.2\n",
    "        learner.sampler=D.WeightedRandomSampler(sweights,epoch_size, replacement=True)\n",
    "#         val_sweights=np.where(validate_ds.dataset.pe_present_on_image[val_folds[fold]],\n",
    "#                   validate_ds.dataset.pe_present_on_image[val_folds[fold]]*4,\n",
    "#                   0.2+np.sin(validate_ds.dataset.rel_slice[val_folds[fold]]*np.pi))\n",
    "#         learner.val_sampler=D.WeightedRandomSampler(val_sweights,int(len(validate_ds)*val_epoch_part), replacement=False)\n",
    "\n",
    "#        learner.load_model(params.path.models)\n",
    "        learner.optimizer = torch.optim.Adam(learner.model.parameters(), lr=1e-4)\n",
    "        learner.init_amp(do_autocast=False)\n",
    "        def new_get_y(self,batch):\n",
    "            return batch[1]\n",
    "        def new_get_x(self,batch):\n",
    "            return batch[:1] \n",
    "        learner.get_y=MethodType(new_get_y, learner)\n",
    "        learner.get_x=MethodType(new_get_x, learner)\n",
    "#        learner.load_checkpoint(params.path.models)\n",
    "\n",
    "\n",
    "        train_dl_args={'shuffle':False,'batch_size':batch_size,'sampler':learner.sampler}\n",
    "        val_dl_args={'shuffle':True}\n",
    "    \n",
    "        for t in range(reps):\n",
    "            learner.scheduler = torch.optim.lr_scheduler.OneCycleLR(learner.optimizer, pct_start=0.01,final_div_factor= 10,\n",
    "                                                                    max_lr=reps_lr[t], steps_per_epoch=epoch_size//batch_size+1, \n",
    "                                                                    epochs=num_epochs//reps)\n",
    "\n",
    "            learner.fit(num_epochs//reps,train_ds,validate_ds,batch_size=batch_size,eval_batch=batch_size,path=params.path.models,\n",
    "                        train_dl_args=train_dl_args,val_dl_args=val_dl_args,num_workers=12)\n",
    "        sandesh.send({'name':learner.name,'best_metric':learner.best_metric})     \n",
    "        learner.save_model(params.path.models)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "ds0=ImageDataset(image_reader,df,transform=transform_val)\n",
    "ds=ImageDataset(image_reader,df,transform=transform)\n",
    "learner.model.last_linear=Noop()\n",
    "featuress=[learner.predict(ds0,batch_size=64,num_workers=20,do_eval=True)]\n",
    "#         featuress=[]\n",
    "sandesh.send({'name':f'finished 1st {SEED} {fold}'})\n",
    "for i in notebook.tqdm(range(0)):\n",
    "#                 learner.model=learner.model.train()\n",
    "    features=learner.predict(ds,batch_size=64,num_workers=12,do_eval=True)\n",
    "    featuress.append(features)\n",
    "    sandesh.send({'name':f'finished {i+1} {SEED} {fold}'})\n",
    "\n",
    "features=np.stack(featuress,0)\n",
    "with open(params.path.features+(name.split('.')[0]+'.pkl'),'wb') as f:\n",
    "    pickle.dump(features,f,protocol=4)\n",
    "sandesh.send({'name':f'saved {features.shape} {SEED} {fold}'})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Sequential(\n",
       "  (wso): SplitCT(\n",
       "    (conv): Conv2d(1, 3, kernel_size=(1, 1), stride=(1, 1))\n",
       "    (sigmoid): Sigmoid()\n",
       "    (norm): InstanceNorm2d(3, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
       "  )\n",
       "  (base_model): AutocastModule(\n",
       "    (module): SENet(\n",
       "      (layer0): Sequential(\n",
       "        (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
       "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu1): ReLU(inplace=True)\n",
       "        (pool): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=True)\n",
       "      )\n",
       "      (layer1): Sequential(\n",
       "        (0): SEResNeXtBottleneck(\n",
       "          (conv1): Conv2d(64, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False)\n",
       "          (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv3): Conv2d(128, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (se_module): SEModule(\n",
       "            (avg_pool): AdaptiveAvgPool2d(output_size=1)\n",
       "            (fc1): Conv2d(256, 16, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (relu): ReLU(inplace=True)\n",
       "            (fc2): Conv2d(16, 256, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (sigmoid): Sigmoid()\n",
       "          )\n",
       "          (downsample): Sequential(\n",
       "            (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          )\n",
       "        )\n",
       "        (1): SEResNeXtBottleneck(\n",
       "          (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False)\n",
       "          (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv3): Conv2d(128, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (se_module): SEModule(\n",
       "            (avg_pool): AdaptiveAvgPool2d(output_size=1)\n",
       "            (fc1): Conv2d(256, 16, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (relu): ReLU(inplace=True)\n",
       "            (fc2): Conv2d(16, 256, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (sigmoid): Sigmoid()\n",
       "          )\n",
       "        )\n",
       "        (2): SEResNeXtBottleneck(\n",
       "          (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False)\n",
       "          (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv3): Conv2d(128, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (se_module): SEModule(\n",
       "            (avg_pool): AdaptiveAvgPool2d(output_size=1)\n",
       "            (fc1): Conv2d(256, 16, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (relu): ReLU(inplace=True)\n",
       "            (fc2): Conv2d(16, 256, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (sigmoid): Sigmoid()\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (layer2): Sequential(\n",
       "        (0): SEResNeXtBottleneck(\n",
       "          (conv1): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=32, bias=False)\n",
       "          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv3): Conv2d(256, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (se_module): SEModule(\n",
       "            (avg_pool): AdaptiveAvgPool2d(output_size=1)\n",
       "            (fc1): Conv2d(512, 32, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (relu): ReLU(inplace=True)\n",
       "            (fc2): Conv2d(32, 512, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (sigmoid): Sigmoid()\n",
       "          )\n",
       "          (downsample): Sequential(\n",
       "            (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "            (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          )\n",
       "        )\n",
       "        (1): SEResNeXtBottleneck(\n",
       "          (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False)\n",
       "          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv3): Conv2d(256, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (se_module): SEModule(\n",
       "            (avg_pool): AdaptiveAvgPool2d(output_size=1)\n",
       "            (fc1): Conv2d(512, 32, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (relu): ReLU(inplace=True)\n",
       "            (fc2): Conv2d(32, 512, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (sigmoid): Sigmoid()\n",
       "          )\n",
       "        )\n",
       "        (2): SEResNeXtBottleneck(\n",
       "          (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False)\n",
       "          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv3): Conv2d(256, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (se_module): SEModule(\n",
       "            (avg_pool): AdaptiveAvgPool2d(output_size=1)\n",
       "            (fc1): Conv2d(512, 32, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (relu): ReLU(inplace=True)\n",
       "            (fc2): Conv2d(32, 512, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (sigmoid): Sigmoid()\n",
       "          )\n",
       "        )\n",
       "        (3): SEResNeXtBottleneck(\n",
       "          (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False)\n",
       "          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv3): Conv2d(256, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (se_module): SEModule(\n",
       "            (avg_pool): AdaptiveAvgPool2d(output_size=1)\n",
       "            (fc1): Conv2d(512, 32, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (relu): ReLU(inplace=True)\n",
       "            (fc2): Conv2d(32, 512, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (sigmoid): Sigmoid()\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (layer3): Sequential(\n",
       "        (0): SEResNeXtBottleneck(\n",
       "          (conv1): Conv2d(512, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=32, bias=False)\n",
       "          (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv3): Conv2d(512, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (se_module): SEModule(\n",
       "            (avg_pool): AdaptiveAvgPool2d(output_size=1)\n",
       "            (fc1): Conv2d(1024, 64, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (relu): ReLU(inplace=True)\n",
       "            (fc2): Conv2d(64, 1024, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (sigmoid): Sigmoid()\n",
       "          )\n",
       "          (downsample): Sequential(\n",
       "            (0): Conv2d(512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "            (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          )\n",
       "        )\n",
       "        (1): SEResNeXtBottleneck(\n",
       "          (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False)\n",
       "          (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv3): Conv2d(512, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (se_module): SEModule(\n",
       "            (avg_pool): AdaptiveAvgPool2d(output_size=1)\n",
       "            (fc1): Conv2d(1024, 64, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (relu): ReLU(inplace=True)\n",
       "            (fc2): Conv2d(64, 1024, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (sigmoid): Sigmoid()\n",
       "          )\n",
       "        )\n",
       "        (2): SEResNeXtBottleneck(\n",
       "          (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False)\n",
       "          (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv3): Conv2d(512, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (se_module): SEModule(\n",
       "            (avg_pool): AdaptiveAvgPool2d(output_size=1)\n",
       "            (fc1): Conv2d(1024, 64, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (relu): ReLU(inplace=True)\n",
       "            (fc2): Conv2d(64, 1024, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (sigmoid): Sigmoid()\n",
       "          )\n",
       "        )\n",
       "        (3): SEResNeXtBottleneck(\n",
       "          (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False)\n",
       "          (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv3): Conv2d(512, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (se_module): SEModule(\n",
       "            (avg_pool): AdaptiveAvgPool2d(output_size=1)\n",
       "            (fc1): Conv2d(1024, 64, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (relu): ReLU(inplace=True)\n",
       "            (fc2): Conv2d(64, 1024, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (sigmoid): Sigmoid()\n",
       "          )\n",
       "        )\n",
       "        (4): SEResNeXtBottleneck(\n",
       "          (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False)\n",
       "          (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv3): Conv2d(512, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (se_module): SEModule(\n",
       "            (avg_pool): AdaptiveAvgPool2d(output_size=1)\n",
       "            (fc1): Conv2d(1024, 64, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (relu): ReLU(inplace=True)\n",
       "            (fc2): Conv2d(64, 1024, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (sigmoid): Sigmoid()\n",
       "          )\n",
       "        )\n",
       "        (5): SEResNeXtBottleneck(\n",
       "          (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False)\n",
       "          (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv3): Conv2d(512, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (se_module): SEModule(\n",
       "            (avg_pool): AdaptiveAvgPool2d(output_size=1)\n",
       "            (fc1): Conv2d(1024, 64, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (relu): ReLU(inplace=True)\n",
       "            (fc2): Conv2d(64, 1024, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (sigmoid): Sigmoid()\n",
       "          )\n",
       "        )\n",
       "        (6): SEResNeXtBottleneck(\n",
       "          (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False)\n",
       "          (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv3): Conv2d(512, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (se_module): SEModule(\n",
       "            (avg_pool): AdaptiveAvgPool2d(output_size=1)\n",
       "            (fc1): Conv2d(1024, 64, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (relu): ReLU(inplace=True)\n",
       "            (fc2): Conv2d(64, 1024, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (sigmoid): Sigmoid()\n",
       "          )\n",
       "        )\n",
       "        (7): SEResNeXtBottleneck(\n",
       "          (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False)\n",
       "          (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv3): Conv2d(512, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (se_module): SEModule(\n",
       "            (avg_pool): AdaptiveAvgPool2d(output_size=1)\n",
       "            (fc1): Conv2d(1024, 64, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (relu): ReLU(inplace=True)\n",
       "            (fc2): Conv2d(64, 1024, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (sigmoid): Sigmoid()\n",
       "          )\n",
       "        )\n",
       "        (8): SEResNeXtBottleneck(\n",
       "          (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False)\n",
       "          (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv3): Conv2d(512, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (se_module): SEModule(\n",
       "            (avg_pool): AdaptiveAvgPool2d(output_size=1)\n",
       "            (fc1): Conv2d(1024, 64, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (relu): ReLU(inplace=True)\n",
       "            (fc2): Conv2d(64, 1024, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (sigmoid): Sigmoid()\n",
       "          )\n",
       "        )\n",
       "        (9): SEResNeXtBottleneck(\n",
       "          (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False)\n",
       "          (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv3): Conv2d(512, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (se_module): SEModule(\n",
       "            (avg_pool): AdaptiveAvgPool2d(output_size=1)\n",
       "            (fc1): Conv2d(1024, 64, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (relu): ReLU(inplace=True)\n",
       "            (fc2): Conv2d(64, 1024, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (sigmoid): Sigmoid()\n",
       "          )\n",
       "        )\n",
       "        (10): SEResNeXtBottleneck(\n",
       "          (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False)\n",
       "          (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv3): Conv2d(512, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (se_module): SEModule(\n",
       "            (avg_pool): AdaptiveAvgPool2d(output_size=1)\n",
       "            (fc1): Conv2d(1024, 64, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (relu): ReLU(inplace=True)\n",
       "            (fc2): Conv2d(64, 1024, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (sigmoid): Sigmoid()\n",
       "          )\n",
       "        )\n",
       "        (11): SEResNeXtBottleneck(\n",
       "          (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False)\n",
       "          (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv3): Conv2d(512, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (se_module): SEModule(\n",
       "            (avg_pool): AdaptiveAvgPool2d(output_size=1)\n",
       "            (fc1): Conv2d(1024, 64, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (relu): ReLU(inplace=True)\n",
       "            (fc2): Conv2d(64, 1024, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (sigmoid): Sigmoid()\n",
       "          )\n",
       "        )\n",
       "        (12): SEResNeXtBottleneck(\n",
       "          (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False)\n",
       "          (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv3): Conv2d(512, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (se_module): SEModule(\n",
       "            (avg_pool): AdaptiveAvgPool2d(output_size=1)\n",
       "            (fc1): Conv2d(1024, 64, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (relu): ReLU(inplace=True)\n",
       "            (fc2): Conv2d(64, 1024, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (sigmoid): Sigmoid()\n",
       "          )\n",
       "        )\n",
       "        (13): SEResNeXtBottleneck(\n",
       "          (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False)\n",
       "          (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv3): Conv2d(512, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (se_module): SEModule(\n",
       "            (avg_pool): AdaptiveAvgPool2d(output_size=1)\n",
       "            (fc1): Conv2d(1024, 64, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (relu): ReLU(inplace=True)\n",
       "            (fc2): Conv2d(64, 1024, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (sigmoid): Sigmoid()\n",
       "          )\n",
       "        )\n",
       "        (14): SEResNeXtBottleneck(\n",
       "          (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False)\n",
       "          (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv3): Conv2d(512, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (se_module): SEModule(\n",
       "            (avg_pool): AdaptiveAvgPool2d(output_size=1)\n",
       "            (fc1): Conv2d(1024, 64, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (relu): ReLU(inplace=True)\n",
       "            (fc2): Conv2d(64, 1024, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (sigmoid): Sigmoid()\n",
       "          )\n",
       "        )\n",
       "        (15): SEResNeXtBottleneck(\n",
       "          (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False)\n",
       "          (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv3): Conv2d(512, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (se_module): SEModule(\n",
       "            (avg_pool): AdaptiveAvgPool2d(output_size=1)\n",
       "            (fc1): Conv2d(1024, 64, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (relu): ReLU(inplace=True)\n",
       "            (fc2): Conv2d(64, 1024, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (sigmoid): Sigmoid()\n",
       "          )\n",
       "        )\n",
       "        (16): SEResNeXtBottleneck(\n",
       "          (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False)\n",
       "          (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv3): Conv2d(512, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (se_module): SEModule(\n",
       "            (avg_pool): AdaptiveAvgPool2d(output_size=1)\n",
       "            (fc1): Conv2d(1024, 64, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (relu): ReLU(inplace=True)\n",
       "            (fc2): Conv2d(64, 1024, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (sigmoid): Sigmoid()\n",
       "          )\n",
       "        )\n",
       "        (17): SEResNeXtBottleneck(\n",
       "          (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False)\n",
       "          (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv3): Conv2d(512, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (se_module): SEModule(\n",
       "            (avg_pool): AdaptiveAvgPool2d(output_size=1)\n",
       "            (fc1): Conv2d(1024, 64, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (relu): ReLU(inplace=True)\n",
       "            (fc2): Conv2d(64, 1024, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (sigmoid): Sigmoid()\n",
       "          )\n",
       "        )\n",
       "        (18): SEResNeXtBottleneck(\n",
       "          (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False)\n",
       "          (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv3): Conv2d(512, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (se_module): SEModule(\n",
       "            (avg_pool): AdaptiveAvgPool2d(output_size=1)\n",
       "            (fc1): Conv2d(1024, 64, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (relu): ReLU(inplace=True)\n",
       "            (fc2): Conv2d(64, 1024, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (sigmoid): Sigmoid()\n",
       "          )\n",
       "        )\n",
       "        (19): SEResNeXtBottleneck(\n",
       "          (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False)\n",
       "          (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv3): Conv2d(512, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (se_module): SEModule(\n",
       "            (avg_pool): AdaptiveAvgPool2d(output_size=1)\n",
       "            (fc1): Conv2d(1024, 64, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (relu): ReLU(inplace=True)\n",
       "            (fc2): Conv2d(64, 1024, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (sigmoid): Sigmoid()\n",
       "          )\n",
       "        )\n",
       "        (20): SEResNeXtBottleneck(\n",
       "          (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False)\n",
       "          (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv3): Conv2d(512, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (se_module): SEModule(\n",
       "            (avg_pool): AdaptiveAvgPool2d(output_size=1)\n",
       "            (fc1): Conv2d(1024, 64, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (relu): ReLU(inplace=True)\n",
       "            (fc2): Conv2d(64, 1024, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (sigmoid): Sigmoid()\n",
       "          )\n",
       "        )\n",
       "        (21): SEResNeXtBottleneck(\n",
       "          (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False)\n",
       "          (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv3): Conv2d(512, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (se_module): SEModule(\n",
       "            (avg_pool): AdaptiveAvgPool2d(output_size=1)\n",
       "            (fc1): Conv2d(1024, 64, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (relu): ReLU(inplace=True)\n",
       "            (fc2): Conv2d(64, 1024, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (sigmoid): Sigmoid()\n",
       "          )\n",
       "        )\n",
       "        (22): SEResNeXtBottleneck(\n",
       "          (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False)\n",
       "          (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv3): Conv2d(512, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (se_module): SEModule(\n",
       "            (avg_pool): AdaptiveAvgPool2d(output_size=1)\n",
       "            (fc1): Conv2d(1024, 64, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (relu): ReLU(inplace=True)\n",
       "            (fc2): Conv2d(64, 1024, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (sigmoid): Sigmoid()\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (layer4): Sequential(\n",
       "        (0): SEResNeXtBottleneck(\n",
       "          (conv1): Conv2d(1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv2): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=32, bias=False)\n",
       "          (bn2): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv3): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (se_module): SEModule(\n",
       "            (avg_pool): AdaptiveAvgPool2d(output_size=1)\n",
       "            (fc1): Conv2d(2048, 128, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (relu): ReLU(inplace=True)\n",
       "            (fc2): Conv2d(128, 2048, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (sigmoid): Sigmoid()\n",
       "          )\n",
       "          (downsample): Sequential(\n",
       "            (0): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "            (1): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          )\n",
       "        )\n",
       "        (1): SEResNeXtBottleneck(\n",
       "          (conv1): Conv2d(2048, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv2): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False)\n",
       "          (bn2): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv3): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (se_module): SEModule(\n",
       "            (avg_pool): AdaptiveAvgPool2d(output_size=1)\n",
       "            (fc1): Conv2d(2048, 128, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (relu): ReLU(inplace=True)\n",
       "            (fc2): Conv2d(128, 2048, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (sigmoid): Sigmoid()\n",
       "          )\n",
       "        )\n",
       "        (2): SEResNeXtBottleneck(\n",
       "          (conv1): Conv2d(2048, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv2): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False)\n",
       "          (bn2): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv3): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (se_module): SEModule(\n",
       "            (avg_pool): AdaptiveAvgPool2d(output_size=1)\n",
       "            (fc1): Conv2d(2048, 128, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (relu): ReLU(inplace=True)\n",
       "            (fc2): Conv2d(128, 2048, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (sigmoid): Sigmoid()\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (avg_pool): AvgPool2d(kernel_size=7, stride=1, padding=0)\n",
       "      (last_linear): Sequential(\n",
       "        (0): NoopAddDim()\n",
       "        (1): AdaptiveMaxPool1d(output_size=256)\n",
       "        (2): NoopSqueezeDim()\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (drop_out): Dropout(p=0.5, inplace=False)\n",
       "  (last_linear): Noop()\n",
       ")"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
